## Stream

Stream 是一个新的强大的支持多播的可持久化消息队列。它有一个消息链表，将所有加入的消息都串起来，每个消息都有一个唯一的 ID 和对应的内容。消息是持久化的，Redis 重启后，内容还在。每个 Stream 都可以挂多个消费组(Consumer Group)，每个消费组会有个游标 last_delivered_id 在 Stream 数组之上往前移动，表示当前消费组已经消费到哪条消息了。每个消费组都有一个 Stream 内唯一的名称，消费组不会自动创建，它需要单独的指令 xgroup_create 进行创建，需要指定从 Stream 的某个消息 ID 开始消费，这个 ID 用来初始化 last_delivered_id 变量。

每个消费组的状态都是独立的，相互不受影响。即同一份 Stream 内部的消息会被每个消费组都消费到。同一个消费组可以挂接多个消费者(Consumer)，这些消费者之间是竞争关系，任意一个消费者读取了消息都会使游标 last_delivered_id 往前移动，每个消费者有一个组内唯一名称。

消费者内部会有一个状态变量 pending_ids，它记录了当前已经被客户端读取，但还没有被 ack 的消息。如果客户端没有 ack，这个变量里面的消息 ID 就会越来越多，一旦某个消息被 ack，它就开始减少。这个 pending_ids 变量在 Redis 官方被称为 PEL，也就是 Pending Entries List，这是一个核心数据结构，它用来确保客户端至少消费了消息一次，而不会在网络传输的中途丢失了而没被处理。

### 消息 ID

消息 ID 的形式是 timestampInMillis-sequence，可以由服务器自动生成，也可以由客户端确定，但是形式必须是"整数-整数"，而后面加入的消息 ID 必须大于前面的消息 ID。

### 消息内容

消息内容就是键值对。

### 增删改查

-   xadd：向 Stream 追加消息
-   xdel：从 Stream 中删除消息，这里的删除仅仅是设置标志位，不影响消息总长度
-   xrange：获取 Stream 中的消息列表，会自动过滤已经删除的消息
-   xlen：获取 Stream 消息长度
-   del：删除整个 Stream 消息列表中的所有消息

### 独立消费

可以在不定义消费组的情况下进行 Stream 消息的独立消费，当 Stream 没有新消息时，甚至可以阻塞等待。Redis 设计 了一个单独的消费指令 xread，可以将 Stream 当成普通的消息队列来使用。

### 创建消费组

Stream 通过 xgroup create 指令创建消费组，创建消费组需要提供起始消息 ID 参数用来初始化 last_delivered_id 变量。

### 消费

Stream 提供了 xreadgroup 指令可以进行消费组的组内消费，需要提供消费组名称、消费者名称和起始消息 ID。它同 xread 一样，也可以阻塞等待新消息。读到新消息后，对应的消息 ID 就会进入消费者的 PEL 结构里，客户端处理完毕后使用 xack 指令通知服务器，本条消息已经处理完毕，该消息 ID 就会从 PEL 中移除。

### Stream 消息太多怎么办

Redis 提供了一个定长的 Stream，在 xadd 的指令中提供一个定长长度参数 maxlen。

### 消息如果忘记 ack 会怎样

Stream 在每个消费者结构中保存了正在处理中的消息 ID 列表 PEL，如果消费者收到了消息，处理完了但是没有回复 ack，就会导致 PEL 列表不断增长，如果有很多消费组，那么这个 PEL 占用的内存就会放大。

### PEL 如何避免消息丢失

PEL 已经保存了发出去的消息 ID，待客户端重新连上之后，可以再次收到 PEL 中的消息 ID 列表。此时 xreadgroup 的起始消息 ID 必须是任意有效的消息 ID，一般将参数设为 0-0，表示读取所有的 PEL 消息以及自 last_delivered_id 之后的新消息。

### Stream 的高可用

Stream 的高可用是建立在主从复制基础上的，它和其他数据结构的复制机制没有区别。

### 分区 Partition

Redis 的服务器没有原生支持分区能力，如果想要使用分区，那就需要分配多个 Stream，然后在客户端使用一定的策略来生产消息到不同的 Stream。

Stream 的消费模型借鉴了 Kafka 的消费分组的概念，弥补了 Redis PubSub 不能持久化消息的缺陷。Stream 又不同于 Kafka，Kafka的消息可以分 Partition，而 Stream 不行。如果非要分 Partition 的话，得在客户端做，提供不同的 Stream 名称，对消息进行 hash 取模来选择往哪个 Stream 里塞。

## Info 指令

Info 指令显示的信息繁多，分为 9 大块，每个块都有非常多的参数：

1.  Server：服务器运行的环境参数
2.  Clients：客户端相关信息
3.  Memory：服务器运行内存统计数据
4.  Persistence：持久化信息
5.  Stats：通用统计数据
6.  Replication：主从复制相关信息
7.  CPU：CPU 使用情况
8.  Cluster：集群信息
9.  KeySpace：键值对统计数量信息

### Redis 每秒执行多少次指令

info stats

### Redis 连接了多少客户端

info clients

### Redis 内存占用多大

info memory

### 复制积压缓冲区多大

info replication。复制积压缓冲区的大小严重影响着主从复制的性能，积压缓冲区是环形的，后来的指令会覆盖掉前面的内容。

## 再谈分布式锁

在 Sentinel 集群中，当主节点挂掉时，从节点会取而代之，但客户端上且没有明显的感知。例如原先第一个客户端在主节点中成功申请了一把锁，但是这把锁还没有来得及同步到从节点，主节点突然挂掉了，然后从节点变成了主节点，这个新的主节点内部没有这个锁，所以当另一个客户端过来请求加锁时，立即就批准了。

不过这种不安全也仅在主从发生 failover 的情况下才会产生，而且持续时间极短，业务系统多数情况下可以容忍。

### Redlock 算法

同很多分布式算法一样，Redlock 也使用"大多数机制"。加锁时，它会向过半节点发送 set 指令，只要过半节点 set 成功，就认为加锁成功。释放锁时，需要向所有节点发送 del 指令。

## 过期策略

Redis 所有的数据结构都可以设置过期时间，时间一到，就会被自动删除。

### 过期的 key 集合

Redis 会将每个设置了过期时间的 key 放入一个独立的字典中，以后会定时遍历这个字典来删除到期的 key。除了定时遍历之外，它还会使用惰性策略来删除过期的 key。所谓惰性策略就是在客户端访问这个 key 的时候，Redis 对 key 的过期时间进行检查，如果过期了就立即删除。如果说定时删除是集中处理，那么惰性删除就是零散处理。

### 定时扫描策略

Redis 默认每秒进行 10 次过期扫描，过期扫描不会遍历过期字典中所有的 key，而是采用了一种简单的贪心策略，步骤如下：

1.  从过期字典中随机选出 20 个 key；
2.  删除这 20 个 key 中已经过期的 key；
3.  如果过期的 key 的比例超过 1/4，那就重复步骤 1。

为了保证过期扫描不会出现循环过度，导致线程卡死的现象，算法还增加了扫描时间的上限，默认不会超过 25ms。

### 从节点的过期策略

从节点不会进行过期扫描，从节点对过期的处理是被动的。主节点在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从节点，从节点通过执行这条 del 指令来删除过期的 key。

## LRU

当 Redis 内存超出物理内存限制时，内存的数据会开始和磁盘产生频繁得交换，交换会让 Redis 的性能急剧下降，对于访问量比较大的 Redis 来说，这样的存取效率基本上等于不可用。为了限制最大使用的内存，Redis 提供了配置参数 maxmemory 来限制内存超出期望大小。Redis 提供了几种可选策略：

1.  noeviction：不会继续服务写请求，读请求可以继续进行。
2.  volatile-lru：尝试淘汰设置了过期时间的 key，最少使用的 key 优先被淘汰。
3.  volatile-ttl：跟上面几乎一样，不过淘汰的策略不是 LRU，而是比较 key 的剩余寿命 ttl 的值。
4.  volatile-random：跟上面几乎一样，不过淘汰的 key 是过期 key 集合中随机的 key。
5.  allkeys-lru：区别于 volatile-lru，这个策略要淘汰的 key 对象是全体的 key 集合，而不只是过期的 key 集合。
6.  allkeys-random：跟上面几乎一样，不过淘汰的 key 是随机的 key。

volatile-xxx 策略只会针对带过期时间的 key 进行淘汰，allkeys-xxx 策略会对所有的 key 进行淘汰。如果你只是拿    Redis 做缓存，那么应该使用 allkeys-xxx 策略，客户端写缓存时不必携带过期时间。如果还想使用 Redis 的持久化功能，那就使用 volatile-xxx 策略，这样可以保留没有设置过期时间的 key，它们是永久的 key，不会被 LRU 算法淘汰。

### LRU 算法

实现 LRU 算法除了需要 key/value 字典外，还需要附加一个链表，链表中的元素按照一定的顺序进行排列。当空间满的时候，会踢掉链表尾部的元素。当字典的某个元素被访问时，它在链表中的位置会被移动到表头，所以链表的元素排列顺序就是元素最近被访问的时间顺序。

### 近似 LRU 算法

Redis 使用了一种近似 LRU 算法，之所以不使用 LRU 算法，是因为其需要消耗大量的额外内存，需要对现有的数据结构进行较大的改造。近似 LRU 算法很简单，在现有数据结构的基础上使用随机采样法来淘汰元素，能达到和 LRU 算法非常近似的效果。Redis 为了实现近似 LRU 算法，给每个 key 增加了一个额外的小字段，这个字段的长度是 24 个 bit，也就是最后一次被访问的时间戳。

当 Redis 执行写操作时，发现内存超出 maxmemory，就会执行一次 LRU 淘汰算法，随机采样出 5 个 key，然后淘汰掉最旧的 key，如果淘汰后内存还是超出 maxmemory，那就继续随机采样淘汰，直到内存低于 maxmemory 为止。

## 懒惰删除

### Redis 为什么使用懒惰删除

如果删除一个非常大的 key 对象，那么删除操作就会导致单线程卡顿。Redis 为了解决这个卡顿问题，引入了 unlink 指令，它能对删除操作进行懒处理，丢给后台线程来异步回收内存。

### flush

Redis 提供了 flushdb 和 flushall 指令，用来清空数据库，这也是极其缓慢的操作。Redis 4.0 同样给这两个指令带来了异步化，在指令后面增加 async。

### 异步队列

主线程将对象引用摘除后，会将这个 key 的内存回收操作包装成一个任务，塞进异步任务队列，后台线程会从这个异步队列中取任务。任务队列被主线程和异步线程同时操作，所以必须是一个线程安全的队列。

### AOF Sync 也很慢

Redis 需要每秒 1 次同步 AOF 日志到磁盘，确保消息尽量不丢失，需要调用 sync 函数，这个操作比较耗时，会导致主线程的效率下降，所以 Redis 也将这个操作移到异步线程来完成。

### 更多异步删除点

除了 del 指令和 flush 操作之外，Redis 在 key 的过期、LRU 淘汰、rename 指令过程中，也会实施回收内存。此外，还有一种特殊的 flush 操作，其发生于正在进行全量同步的从节点中，在接受完整的 rdb 文件后，也需要将当前的内存一次性清空，以加载整个 rdb 文件的内容到内存。

Redis 4.0 为这些删除点也带来了异步删除机制，打开这些点需要额外的设置选项。

1.  slave-lazy-flush：从节点接受完 rdb 文件后的 flush 操作
2.  lazyfree-lazy-eviction：内存达到 maxmemory 时进行淘汰
3.  lazyfree-lazy-expire key：过期删除
4.  lazyfree-lazy-server-del rename：指令删除 destKey

## 保护 Redis

### 指令安全

Redis 在配置文件中提供了 rename-command 指令用于将某些危险的指令修改成特别的名称，用来避免人为误操作。

### 端口安全

运维会在 Redis 的配置文件中指定监听的 IP 地址。还可以增加 Redis 的密码访问限制，客户端逼旭使用 auth 指令，传入正确的密码才可以访问 Redis。密码控制也会影响到从节点复制，从节点必须在配置文件里使用 masterauth 指令配置相应的密码才可以进行复制操作。

### Lua 脚本安全

开发者必须禁止 Lua 脚本由用户输入的内容生成，同时应该让 Redis 以普通用户的身份启动。

### SSL 代理

SSL 代理比较常见的有 ssh，不过 Redis 官方推荐使用 spiped 工具。

## Redis 安全通信

### spiped 原理

spiped 会在客户端和服务器各启动一个 spiped 进程。发送端的 spiped 进程负责接受来自 Redis Client 发送过来的请求数据，加密后传送到接收端的 spiped 进程。接收端的 spiped 进程将接收到的数据解密后传递到 Redis Server。然后 Redis Server 再走一个反向的流程将响应回复给 Redis Client。