## 探索"字符串"内部

Redis 中的字符串是可以修改的字符串，在内存中它是以字节数组的形式存在的。在 Redis 里面，字符串叫做"SDS"，也就是 Simple Dynamic String。它的结构是一个带长度信息的字节数组。

```c++
struct SDS<T> {
  T capacity;		//数组容量
  T len;		//数组长度
  byte flags;		//特殊标志位
  byte[] content;		//数组内容
}
```

capacity 表示所分配数组的长度，len 表示字符串的实际长度。字符串是可以修改的字符串，要支持 append 操作。

```c++
sds sdscatlen(sds s, const void *t, size_t len) {
  size_t curlen = sdslen(s);		//原字符串长度
  
  //按需调整空间，如果 capacity 不够容纳追加的内容，就会重新分配字节数组并复制原字符串的内容到新数组中
  s = sdsmakeRoomFor(s, len);
  if (s == NULL) return NULL;		//内存不足
  memcpy(s + curlen, t, len);		//追加目标字符串的内容到字节数组中
  sdssetlen(s, curlen + len);		//设置追加后的长度值
  s[curlen + len] = '\0';		//让字符串以 \0 结尾，便于调试打印，还可以直接使用 glibc 的字符串函数进行操作
  return s;
}
```

上面的 SDS 结构使用了泛型 T。为什么不直接使用 int？因为当字符串比较短时，len 和 capacity 可以使用 byte 和 short 来表示，Redis 为了对内存做极致的优化，不同长度的字符串使用不同的结构体来表示。Redis 规定字符串的长度不超过 512 MB。

### embstr VS raw

Redis 的字符串有两种存储方式，在长度特别短时，使用 embstr 形式存储(embeded)，而当长度超过 44 字节时，使用 raw 形式存储。

Redis 对象头结构：

```c
struct RedisObject {
  int4 type;					//4bits
  int4 encoding;			//4bits
  int24 lru;					//24bits
  int32 refcount;			//4bytes
  void *ptr;					//8bytes,64-bit system
} robj;
```

SDS 结构体的大小，在字符串比较小时，SDS 对象头结构的大小是 capacity + 3，至少是 3 字节。意味着分配一个字符串的最小空间占用是 19 字节。

```c
struct SDS {
  int8 capacity;		//1byte
  int8 len;					//1byte
  int8 flags;				//1byte
  byte[] content;		//长度为capacity
}
```

embstr 存储形式是这样一种存储形式，它将 RedisObject 对象头结构和 SDS 对象连续存在一起，使用 malloc 方法一次分配，而 raw 存储形式不一样，它需要使用两次 malloc 方法，两个对象头在内存地址上一般是不连续的。

内存分配器 jemalloc、tcmalloc 等分配内存大小的单位都是 2/4/8/16/32/64 字节等，为了能容纳一个完整长度的 embstr 对象，jemalloc 最少会分配 32 字节的空间，如果字符串再稍微长一点，那就是 64 字节的空间。如果字符串总体超出了 64 字节，Redis 认为它是一个大字符串，不再适合使用 emdstr 形式存储，而该使用 raw 形式。当内存分配器分配了 64 字节空间时，字符串最大长度就是 44 字节。

### 扩容策略

在字符串长度小于 1MB 之前，扩容空间采用加倍策略，当字符串长度超过 1MB 之后，为了避免加倍后的冗余空间过大而导致浪费，每次扩容只会多分配 1MB 大小的冗余空间。

## 探索"字典"内部

字典是 Redis 服务器中出现最为频繁得复合型数据结构，除了 hash 结构的数据会用到字典(dict)外，整个 Redis 数据库的所有 key 和 value 也组成了一个全局字典，还有带过期时间的 key 集合也是一个字典。zset 集合中存储 value 和 score 值的映射关系也是通过字典结构实现的。

### 字典内部结构

字典结构内部包含两个 hashtable，通常情况下只有一个 hashtable 是有值的，但是在字典扩容缩容时，需要分配新的 hashtable，然后进行渐进式搬迁，这时候两个 hashtable 存储的分别是旧的 hashtable 和新的 hashtable。待搬迁结束后，旧的 hashtable 被删除，新的 hashtable 取而代之。

hashtable 的结构和 Java 的 HashMap 几乎是一样的，都是通过分桶的方式解决 hash 冲突。第一维是数组，第二维是链表。

### 渐进式 rehash

Redis 使用渐进式 rehash 小步搬迁。

```c
dictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing) {
    long index;
    dictEntry *entry;
    dictht *ht;

    //这里进行小步搬迁
    if (dictIsRehashing(d)) _dictRehashStep(d);

    if ((index = _dictKeyIndex(d, key, dictHashKey(d, key), existing)) == -1) return NULL;


    //如果字典处于搬迁过程中，要将新的元素挂接到新的数组下面
    ht = dictIsRehashing(d) ? &d->ht[1] : &d->ht[0];
    entry = zmalloc(sizeof(*entry));
    entry->next = ht->table[index];
    ht->table[index] = entry;
    ht->used++;

    dictSetKey(d, entry, key);
    return entry;
}
```

搬迁操作在当前字典的后续操作当中(来自客户端的 hset、hdel 等指令)，但是有可能客户端闲下来了，却没有后续指令来触发这个搬迁，那么这时就会在定时任务中对字典进行主动搬迁。

### 查找过程

```c
func get(key) {
    let index = hash_func(key) % size;
    let entry = table[index];
    while (entry != NULL) {
        if (entry.key == target) {
            return entry.value;
        }
        entry = entry.next;
    }
}
```

代码中 hash_func，会将 key 映射为一个整数，不同的 key 会被映射成分布比较均匀散乱的整数。只有 hash 值均匀了，整个 hashtable 才是平衡的，所有的二维链表的长度就不会差距很远，查找算法的性能也就比较稳定。

### hash 函数

hashtable 的性能好不好完全取决于 hash 函数的质量。Redis 的字典默认的 hash 函数是 siphash。siphash 算法即使在输入 key 很小的情况下，也可以产生随机性特别好的输出。

### hash 攻击

如果 hash 函数存在偏向性，在特定模式下的输入会导致 hash 第二维链表长度极为不均匀，甚至所有的元素都集中到个别链表中，直接导致查找效率急剧下降。

### 扩容条件

正常情况下，当 hash 表中元素的个数等于第一维数组的长度时，就会开始扩容，扩容的数组是原数组大小的 2 倍。

### 缩容条件

当 hash 表因为元素逐渐被删除变得越来越稀疏时，Redis 会对 hash 表进行缩容来减少 hash 表的第一维数据空间占用。缩容的条件是元素个数低于数组长度的 10%。缩容不会考虑 Redis 是否正在做 bgsave。

### set 的结构

Redis 里面 set 的结构底层实现也是字典，只不过所有的 value 都是 NULL，其他特性和字典一模一样。

## 探索"压缩列表"内部

Redis 为了节省内存空间使用，zset 和 hash 容器对象在元素个数比较少的时候，采用压缩列表(ziplist)进行存储。压缩列表是一块连续的内存空间，元素之间紧挨着存储，没有任何冗余空隙。

```c
struct ziplist<T> {
  int32 zlbytes;		//整个压缩列表占用字节数
  int32 zltail_offset;		//最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点
  int16 zllength;		//元素个数
  T[] entries;		//元素内容列表，依次紧凑存储
  int8 zlend;		//标志压缩列表的结束，值恒为0xff
}
```

压缩列表为了支持双向遍历，所以才会有 ztail_offset 这个字段，用来快速定位到最后一个元素，然后倒着遍历。

entry 块随着容纳的元素类型不同，也会有不一样的结构。

```c
struct entry {
  int<var> prevlen;		//前一个entry的字节长度
  int<var> encoding;		//元素类型编码
  optional byte[] content;		//元素内容
}
```

prevlen 字段表示前一个 entry 的字节长度，当压缩列表倒着遍历时，需要通过这个字段快速定位到下一个元素的位置。它是一个变长的整数，当字符串长度小于 254 即(0xFF)时，使用一个字节表示；如果达到或超出 254 时，就使用 5 个字节来表示。第一个字节是 0xFE，剩余四个字节表示字符串长度。

Encoding 字段存储了元素内容的编码类型信息，ziplist 通过这个字段来决定后面的 content 的形式。

Redis 为了节约存储空间，通过前缀位来识别具体存储的数据形式。

1.  00xxxxxx 是最大长度位数为 63 的短字符串，后面的 6 个位存储字符串的位数，剩余的字节就是字符串的内容。
2.  01xxxxxx xxxxxxxx 是中等长度的字符串，后面 14 个位来表示字符串的长度，剩余的字节就是字符串的内容。
3.  10000000 aaaaaaaa bbbbbbbb cccccccc dddddddd 是特大字符串，需要使用额外 4 个字节来表示长度。第一个字节前缀是 10，剩余 6 位没有使用，统一置为零。后面跟着字符串内容。不过这样的大字符串是没有机会使用的，压缩列表通常只是用来存储小数据的。
4.  11000000 表示 int16，后跟两个字节表示整数。
5.  11010000 表示 int32，后跟四个字节表示整数。
6.  11100000 表示 int64，后跟八个字节表示整数。
7.  11110000 表示 int24，后跟三个字节表示整数。
8.  11111110 表示 int8，后跟三个字节表示整数。
9.  11111111 表示 ziplist 的结束，也就是 zlend 的值 0xFF。
10.  1111xxxx 表示极小整数，xxxx 的范围只能是(0001-1101)，也就是1-13，因为 0000、1110、1111 都被占用了。读取到的 value 需要将 xxxx 减 1，也就是说整数 0-12 就是最终的 value。

### 增加元素

因为 ziplist 都是紧凑存储，没有冗余空间，意味着插入一个新的元素就需要调用 realloc 扩展内存。取决于内存分配器算法和当前的 ziplist 内存大小，realloc 可能会重新分配新的内存空间，并将之前的内容一次性拷贝到新的地址，也有可能在原有的地址上进行扩展。如果 ziplist 占据内存太大，重新分配内存和拷贝内存就会有很大的消耗，所以 ziplist 不适合存储大型字符串，存储的元素也不宜过多。

### 级联更新

每个 entry 都会有一个 prevlen 字段存储前一个 entry 的长度。如果内容小于 254 字节，prevlen 就用 1 字节存储，否则就用 5 字节存储。这意味着如果某个 entry 经过了修改操作从 253 字节变成了 254 字节，那么它的下一个 entry 的 prevlen 字段就要更新，从 1 个字节扩展到 5 个字节。如果 ziplist 里面的每个 entry 恰好都存储了 253 字节的内容，那么第一个 entry 内容的修改就会导致后续所有 entry 的级联更新，这就是一个比较耗费计算资源的操作。

### intset小整数集合

当 set 集合容纳的元素都是整数并且元素个数较少时，Redis 会使用 intset 来存储集合元素。intset 是紧凑的数组结构，同时支持 16 位、32 位和 64 位整数。

```c
struct intset<T> {
  int32 encoding;		//决定整数位宽是16位、32位还是64位
  int32 length;		//元素个数
  int<T> contents;		//整数数组，可以是16位、32位和64位
}
```

## 探索"快速列表"内部

quicklist 是 ziplist 和 linkedlist 的混合体，它将 linkedlist 按段切分，每一段使用 ziplist 让存储紧凑，多个ziplist 之间使用双向指针串接起来。为了进一步节省空间，Redis 还会对 ziplist 进行压缩存储，使用 LZF 算法压缩，可以选择压缩深度。

### 每个 ziplist 存多少元素

quicklist 内部默认单个 ziplist 长度为 8KB，超出了这个字节数，就会另起一个 ziplist。ziplist 的长度由配置参数 list-max-ziplist-size 决定。

### 压缩深度

quicklist 默认的压缩深度是 0，也就是不压缩。压缩的实际深度由配置参数 list-compress-depth 决定。为了支持快速的 push/pop 操作，quicklist 的首尾两个 ziplist 不压缩，此时压缩深度就是 1。

## 探索"跳跃列表"内部

zset 的内部实现是一个 hash 字典加一个跳跃列表(skiplist)。

### 基本结构

Redis 的跳跃列表共有 64 层，理论上能够容纳 $2^{64}$个元素。

### 查找过程

跳跃列表有了多层结构之后，这个定位的算法复杂度将会降到$O(lg(n))$。

### 随机层数

对于每个新插入的节点，都需要调用一个随机算法给它分配一个合理的层数。Redis 标准源码中的晋升率只有 25%，也就是代码中的 ZSKIPLIST_P 的值。所以官方的跳跃列表更加的扁平化，层高相对较低，在单个层上需要遍历的节点数量会稍多一些。

也正是因为层数一般不高，所以遍历的时候从顶层开始往下遍历会非常浪费。跳跃列表会记录一下当前的最高层数 maxLevel，遍历时从这个 maxLevel 开始遍历，性能就会提高很多。

### 插入过程

首先在搜索合适插入点的过程中将"搜索路径"找出来，然后就可以开始创建新节点。创建的时候需要给这个节点随机分配一个层数，再将搜索路径上的节点和这个新节点通过前向后向指针串起来。如果分配的新节点的高度高于当前跳跃列表的最大高度，就需要更新一下跳跃列表的最大高度。

### 删除过程

删除过程和插入过程类似，都需先把这个"搜索路径"找出来，然后对于每个层的相关节点重排一下前向后向指针，同时还要注意更新一下最高层数 maxLevel。

### 更新过程

当调用 zadd 方法时，如果对应的 value 不存在，那就是插入过程。如果这个 value 已经存在了，只是调整一下 score 的值，那就需要走一个更新流程。假设这个新的 score 值不会带来排序上的改变，那么就不需要调整位置，直接修改元素的 score 值就可以了。但是如果排序位置改变了，就要调整位置。一个简单的策略就是先删除这个元素，再插入这个元素，需要经过两次路径搜索。Redis 遇到 score 值改变了的情况就直接删除后再插入，不会判断位置是否需要调整。

### 如果 score 值都一样

Zset 的排序元素不只看 score 值，如果 score 值相同还需要再比较 value 值。

### 元素排名是怎么算出来的

Redis 在 skiplist 的 forward 指针上进行了优化，给每一个 forward 指针都增加了 span 属性，span 是"跨度"的意思，表示从当前层的当前节点沿着 forward 指针跳到下一个节点中间会跳过多少节点。Redis 在插入、删除操作时会小心翼翼地更新 span 值的大小。

```c
struct zslforward {
  zslnode *item;
  long span;
}

struct zslnode {
  String value;
  double score;
  zslforward*[] forwards;		//多层连接指针
  zslnode* backward;		//回溯指针
}
```

当要计算一个元素的排名时，只需要将"搜索路径"经过所有节点的跨度 span 值进行叠加就可以算出元素的最终 rank 值。

## 探索"紧凑列表"内部

Redis 5.0 版本又引入了一个新的数据结构 listpack，它是对 ziplist 结构的改进版，在存储空间上会更加节省，而且结构上也比 ziplist 更精简。

```c
struct listpack<T> {
  int32 total_bytes;		//占用的总字节数
  int16 size;		//元素个数
  T[] entries;		//紧凑排列的元素列表
  int8 end;			//同zlend一样，恒为0xFF
}
```

listpack 跟 ziplist 的结构几乎一模一样，只是少了一个 zltail_offset 字段。ziplist 通过这个字段来定位出最后一个元素的位置，用于逆序遍历，不过 listpack 也可以通过其他方式定位出最后一个元素的位置。

```c
struct lpentry {
  int<var> encoding;
  optional byte[] content;
  int<var> length;
}
```

listpack 的元素结构和 ziplist 的元素结构也很类似，都包含三个字段，不同的是，前者的长度字段放在了元素的尾部，而且存储的不是上一个元素的长度，是当前元素的长度。正是因为长度放在了尾部，所以可以省去用于标记最后一个元素位置的 zltail_offset 字段，最后一个元素的位置可以通过 total_bytes 字段和最后一个元素的长度字段计算出来。

listpack 的长度字段使用 varint 进行编码。不同于 skiplist 元素长度的编码只能是 1 个字节或者 5 个字节，listpack 元素长度的编码可以是 1~5 个字节中的任一长度。同 UTF-8 编码一样，它通过字节的最高位是否为 1 来决定编码的长度。

### 级联更新

listpack 的设计彻底消灭了 ziplist 存在的级联更新行为，元素与元素之间完全独立，不会因为一个元素的长度变长就导致后续的元素内容受到影响。

## 探索"基数树"内部

rax 是 Redis 内部比较特殊的一个数据结构，它是一个有序字典树(基数树 Radix Tree)，按照 key 的字典序排序，支持快速定位、插入和删除操作。Redis 五大基础数据结构里面，能作为字典使用的有 hash 和 zset。hash 不具备排序功能，zset 则是按照 score 进行排序的。rax 跟 zset 的不同在于它是按照 key 进行排序的。

rax 中有非常多的节点，分为根节点、叶子节点和中间节点三种。有些中间节点带有 value，有些中间节点则纯粹是结构性需要，没有对应的 value。

```c
struct raxNode {
  int<1> isKey;		//是否有key，没有key的是根节点
  int<1> isNull;		//没有对应的value，是无意义的中间节点
  int<1> isCompressed;		//是否压缩存储，这个压缩的概念比较特别
  int<29> size;		//叶子节点的数量或者是压缩字符串的长度(isCompressed)
  byte[] data;		//路由键、叶子节点指针、value都在这里
}
```

rax 是一棵比较特殊的 Radix Tree，它在结构上不是标准的 Radix Tree。如果一个中间节点有多个叶子节点，那么路由键就只是一个字符，如果只有一个叶子节点，那么路由键就是一个字符串。

raxNode.data 是一个比较复杂的结构，按照压缩与否分为两种。

压缩结构：如果叶子节点只有一个，就是压缩结构

```c
struct data {
  optional struct {		//取决于header的size字段是否为零
    byte[] childkey;		//路由键
    raxNode* childNode;		//子节点指针
  } child;
  optional string value;		//取决于header的isNull字段
}
```

如果是叶子节点，child 字段就不存在。如果是无意义的中间节点(isNull)，那么 value 字段就不存在。

非压缩节点：如果叶子节点有多个，那就不是压缩结构，存在多个路由键，一个键是一个字符。

```c
struct data {
  byte[] childKeys;		//路由键字符列表
  raxNode*[] childNodes;	//多个叶子节点指针
  optional string value;		//取决于header的isNull字段
}
```

## LFU VS LRU

LFU 的全称是 Least Frequently Used，表示按最近的访问频率进行淘汰，它比 LRU 更加精准地表示了一个 key 被访问的热度。

### Redis 对象的热度

```c
//Redis 的对象头结构
typedef struct redisObject {
  unsigned type:4;		//对象类型如zset、set、hash等
  unsigned encoding:4;		//对象编码如ziplist、intset、skiplist等
  int refcount;		//引用计数
  void *ptr;		//对象的body
} robj;
```

### LRU 模式

在 LRU 模式下，lru 字段存储的是 Redis 时钟 server.lruclock。Redis 时钟是一个 24bit 的整数，默认是 Unix 时间戳对 $2^{24}$取模的结果，大约 97 天清零一次。当某个 key 被访问一次，它的对象头结构的 lru 字段值就会被更新为 server.lruclock。

默认 Redis 时钟值每毫秒更新一次，在定时任务 serverCron 里主动设置。Redis 的很多定时任务都是在 serverCron 里面完成的。

如果 server.lrulock 没有折返(对$2^{24}$取模)，它就是一直递增的，这意味着对象的 lru 字段不会超过 server.lrulock 的值。如果超过了，说明 server.lruclock 折返了。通过这个逻辑就可以精准计算出对象多长时间没有被访问——即"对象的空闲时间"。

### LFU 模型

在 LFU 模式下，lru 字段 24 bit 用来存储两个值，分别是 ldt(last decrement time)和 logc(logistic counter)。

logc 是 8 个 bit，用来存储访问频次，因为 8 个 bit 能表示的最大整数值为 255，存储频次肯定不够，所以这 8 个  bit 存储的是频次的对数值，并且这个值还会随时间衰减，如果它的值比较小，那么就很容易被回收。为了确保新创建的对象不被回收，新对象的这 8 个 bit 会被初始化一个大于零的值 LFU_INT_VAL(默认是=5)。

ldt 是 16 个 bit，用来存储上一次 logc 的更新时间，因为只有 16 个 bit，所以精度不可能很高。它取的是分钟时间戳对$2^{16}$进行取模，大约每隔 45 天就会折返。

ldt 的值和 LRU 模式的 lru 字段不一样的地方是，ldt 不是在对象被访问时更新的，而是在 Redis 的淘汰逻辑进行时进行更新，淘汰逻辑只会在内存达到 maxmemory 的设置时才会触发，在每一个指令的执行之前都会触发。每次淘汰都是采用随机策略，随机挑选若干个 key，更新这个 key 的"热度"，淘汰掉"热度"最低的 key。因为 Redis 采用的是随机算法，如果 key 比较多的话，那么 ldt 更新得可能会比较慢。

ldt 更新的同时也会一同衰减 logc 的值。衰减也有特定的算法，它将现有的 logc 值减去对象的空闲时间(分钟数)，再除以一个衰减系数 lfu_decay_time(默认为1)。如果 lfu_decay_time 的值大于 1，那么就会衰减的比较慢，如果它等于零，那就表示不衰减，lfu-decay-time 可以进行设置。

### 为什么 Redis 要缓存系统时间戳

每一次获取系统时间戳都是一次系统调用，比较费时，所以需要缓存时间，获取时间直接从缓存中拿。

### Redis 为什么在获取 lruclock 时使用原子操作

因为 Redis 实际上并不是单线程，背后还有几个异步线程也在默默工作，这几个线程也要访问 Redis 时钟，所以 lruclock 字段是需要支持多线程读写的。使用 atomic 读写能保证多线程 lruclock 数据的一致性。



